library(tidyverse)
library(readxl)
library(lubridate)


#This is a current work in progess
#6/13/2018


# this code takes the 3rd party call for data continuous datasets and generates
# Summary statistics. Output is a file to load into AWQMS




#clean out exisiting environment
#helps to avoid overwriting
rm(list = ls())

#Choose submitted file
filepath <- file.choose()


Results_import <- read_excel(filepath, sheet = "Results")
colnames(Results_import) <- make.names(names(Results_import), unique=TRUE)


#convert F to C, filter out rejected data, and create datetime column
results_data <- Results_import %>%
  mutate(r = ifelse(Result.Unit == "deg F", round((Result.Value - 32)*(5/9),2), Result.Value),
         r_units = ifelse(Result.Unit == "deg F", "deg C", Result.Unit )) %>%
  filter(Result.Status.ID != "Rejected") %>%
  mutate(time_char = strftime(Activity.Start.Time, format = "%H:%M:%S", tz = 'UTC'),
         datetime = ymd_hms(paste(Activity.Start.Date, time_char)))


unique_characteritics <- unique(Results_import$Characteristic.Name)

#create list for getting data out of loop
sumstatlist <- list()


for (i in 1:length(unique_characteritics)){
  
  char <- unique_characteritics[i]
  
  results_data_char <- results_data %>%
    filter(Characteristic.Name == char) %>%
    mutate(hr =  format(datetime, "%Y-%j-%H"))
  
  # Simplify to hourly values and Stats
  hrsumna <- results_data_char %>%
    group_by(Monitoring.Location.ID, Equipment.ID.., hr, r_units, Activity.Start.End.Time.Zone) %>%
    summarise(date = mean(Activity.Start.Date),
              hrDTmin = min(datetime),
              hrDTmax = max(datetime),
              hrN = sum(!is.na(r)),
              hrMean = mean(r, na.rm=TRUE),
              hrMin = min(r, na.rm=TRUE),
              hrMax = max(r, na.rm=TRUE))
  
  # Warnings are OK but need to run NA assignments below
  hrsumna$hrMin[which(is.infinite(hrsumna$hrMin))] <- NA
  hrsumna$hrMax[which(is.infinite(hrsumna$hrMax))] <- NA
  
  
  #########################
  # #
  #  #
  #   # 
  #  #  
  ##  aily stats
  ##########################
  
  # For each date, how many hours have hrN > 0
  # remove rows with zero records in an hour.
  hrdat<- hrsumna[which(hrsumna$hrN >0),]

  # Summarise to daily statistics
   daydat <- hrdat %>%
    group_by(Monitoring.Location.ID, Equipment.ID.., date, r_units, Activity.Start.End.Time.Zone) %>%
    summarise(  dDTmin = min(hrDTmin),
                dDTmax = max(hrDTmax),
                hrNday = length(hrN), 
                dyN = sum(hrN),
                dyMean = mean(hrMean, na.rm=TRUE),
                dyMin = min(hrMin, na.rm=TRUE),
                dyMax = max(hrMax, na.rm=TRUE)
               )
  

   # set cmts for periods with less than 24 hours of data
   daydat <- daydat %>%
     rowwise() %>%
     mutate(ResultStatusID = ifelse(hrNday > 20, 'Final', "Rejected")) %>%
     mutate(cmnt =ifelse(hrNday > 22, "Generated by ORDEQ", ifelse(hrNday < 22 & hrNday > 20, 
                                                                   paste0("Generated by ORDEQ; Estimated - ", as.character(hrNday), ' hrs with valid data in day' ), 
                                                                   paste0("Generated by ORDEQ; Rejected - ", as.character(hrNday), ' hrs with valid data in day' )) ))  
                         
    
  #get daily median values
   dm <- results_data_char %>%
     ungroup() %>%
     group_by(Monitoring.Location.ID, Equipment.ID.., Activity.Start.Date) %>%
     summarise(dyMedian = median(r))
   
   daydat <- daydat %>%
     left_join(dm, by = c("Monitoring.Location.ID", "date" = "Activity.Start.Date"))
   
   ##########
   #   #
   ## ##
   # # #
   #   # oving Averages
   #########
   
   
   # create column for moving average calculations
   daydat$ma <- NA
   daydat$anaStart <- as.POSIXct(NA)# Add analysis start and end dates
   daydat$anaEnd <- as.POSIXct(NA)
  
    ##  DISSOLVED OXYGEN 
   ############ This is where we would generate stats for DO sat
   if (results_data_char$Characteristic.Name[1]  %in% c('DO','adjDO','DOs', "Dissolved oxygen (DO)")) {
     # remove data with bad dDQL's and get daily minimum value
     daydat$r4ma <- ifelse(daydat$ResultStatusID == 'Rejected' | is.na(daydat$ResultStatusID), NA, daydat$dyMin ) 
     for (j in 1:length(daydat$date)) {
       if (j < 30) {
         daydat$ma[j]<- as.numeric(NA)
       } else if (j >29 && (daydat$dDTmax[j] - daydat$dDTmin[j-29])<= 30.03) { # needs to be after the 30th day and should only span 30 days, the .03 accounts for time changes in fall .
         daydat$anaStart[j] <- as.character(daydat$dDTmin[j-29]) # careful that the local time zone doesn't mess this up
         daydat$anaEnd[j] <- as.character(daydat$dDTmax[j]) # careful that the timeshift doesn't mess this up
         ifelse(sum(is.na(daydat$r4ma[(j-29):j])) > 3, NA, # if more than 3 missing days than no calculation
                daydat$ma[j] <- mean(daydat$r4ma[(j-29):j], na.rm = TRUE))
       }
     }
   }
   
   ##  TEMPERATURE
   if (results_data_char$Characteristic.Name[1] %in% c('TEMP','adjTEMP', 'Temperature, water' )) {
     # remove data with bad dDQL's and get daily minimum value
     daydat$r4ma <- ifelse(daydat$ResultStatusID == 'Rejected' | is.na(daydat$ResultStatusID), NA, daydat$dyMax ) 
     for (j in 1:length(daydat$date)) {
       if (j < 7) {
         daydat$ma[j]<- as.numeric(NA)
       } else if (j > 6 && (daydat$dDTmax[j] - daydat$dDTmin[j-6]) <= 7.03) { # needs to be after the 6th day and should only span 7 days, the .03 accounts for time changes in fall .
         daydat$anaStart[j] <- as.character(daydat$dDTmin[j-6]) # careful that the default time zone doesn't mess this up
         daydat$anaEnd[j] <- as.character(daydat$dDTmax[j]) # careful that the the default time zone doesn't mess this up
         ifelse(sum(is.na(daydat$r4ma[(j-6):j])) > 1, NA, # if more than on missing day then no calculation
                daydat$ma[j] <- mean(daydat$r4ma[(j-6):j], na.rm = TRUE))
       }
     }
   }
   
   
   # Add deployment metadata
   daydat <- daydat %>%
     mutate(charID = char) 
   
   sumstatlist[[i]] <- daydat   
 
   
   
    }
  
sumstat <- bind_rows(sumstatlist)


#gather wide file to long format

sumstat_long <- sumstat %>%
  gather('dyMean', 'dyMin', 'dyMax', 'dyMedian', 'ma',  key = "StatisticalBasis", value = "Result") %>%
  arrange(Monitoring.Location.ID, date) %>%
  filter(!is.na(Result)) %>%
  select(-Equipment.ID...y) %>%
  rename(Equipment = Equipment.ID...x)
  

#read audit data

Audit_import <- read_excel(filepath, sheet = "Audit_Data")
colnames(Audit_import) <- make.names(names(Audit_import), unique=TRUE)

Audits <- Audit_import %>%
  filter(!is.na(Project.ID))

Audits_unique <- unique(Audits[c("Project.ID", "Monitoring.Location.ID", "Equipment.ID..", "Characteristic.Name", "Result.Analytical.Method.ID")])

sumstat_long <- sumstat_long %>%
  left_join(Audits_unique, by = c("Monitoring.Location.ID", "charID" = "Characteristic.Name", "Equipment" = "Equipment.ID..") )

AQWMS_sum_stat <- sumstat_long %>%
  mutate(RsltTimeBasis = ifelse(StatisticalBasis == "ma", "7 Day", "1 Day" ),
         ActivityType = "FMC",
         SmplColMthd = "ContinuousPrb",
         SmplColEquip = "Probe/Sensor",
         SmplDepth = "",
         SmplDepthUnit = "",
         SmplColEquipComment = "",
         Samplers = "",
         Project = Project.ID,
         AnaStartDate = ifelse(StatisticalBasis == "ma", format(anaStart, "%Y-%m-%d"), format(date, "%Y-%m-%d")),
         AnaStartTime = ifelse(StatisticalBasis == "ma", format(anaStart, "%H:%M:%S"), format(date, "%H:%M:%S")),
         AnaEndDate = ifelse(StatisticalBasis == "ma", format(anaEnd, "%Y-%m-%d"),format(dDTmax, "%Y-%m-%d")),
         AnaEndTime = ifelse(StatisticalBasis == "ma", format(anaEnd, "%H:%M:%S"),  format(dDTmax, "%H:%M:%S")),
         ActStartDate = format(dDTmin, "%Y-%m-%d"),
         ActStartTime = format(dDTmin, "%H:%M:%S"),
         ActEndDate = format(dDTmax, "%Y-%m-%d"),
         ActEndTime = format(dDTmax, "%H:%M:%S"),
         RsltType = "Calculated",
         ActStartTimeZone = Activity.Start.End.Time.Zone,
         ActEndTimeZone = Activity.Start.End.Time.Zone,
         AnaStartTimeZone = Activity.Start.End.Time.Zone,
         AnaEndTimeZone = Activity.Start.End.Time.Zone
         ) %>%
  select(charID,
         Result,
         r_units,
         Result.Analytical.Method.ID,
         RsltType,
         ResultStatusID,
         StatisticalBasis,
         RsltTimeBasis,
         cmnt,
         ActivityType,
         Monitoring.Location.ID,
         SmplColMthd,
         SmplColEquip,
         SmplDepth,
         SmplDepthUnit,
         SmplColEquipComment,
         Samplers,
         Equipment,
         Project,
         ActStartDate,
         ActStartTime,
         ActStartTimeZone,
         ActEndDate,
         ActEndTime,
         ActEndTimeZone,
         AnaStartDate,
         AnaStartTime,
         AnaStartTimeZone,
         AnaEndDate,
         AnaEndTime,
         AnaEndTimeZone)


