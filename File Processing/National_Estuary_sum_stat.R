library(tidyverse)
library(readxl)
library(lubridate)
library(openxlsx)
library(zoo)


# Setup -------------------------------------------------------------------

# clean out exisiting environment
# helps to avoid overwriting
rm(list = ls())

options(scipen=999)


path <- "A:/Integrated_Report/DataSources/NationalEstuarineResearch/331891/FilesforAWQMS/"

in_fnames <- list.files(path, full.names = TRUE)
in_fnames <- in_fnames[grep("wq", in_fnames)]

for(h in 1:length(in_fnames)){

  print(paste("Starting file", h, "of",length(in_fnames) ))
  
  filepath = in_fnames[h]

data_import <- read.csv(filepath, stringsAsFactors = FALSE) %>%
  select(StationCode, DateTimeStamp, Temp, F_Temp, DO_Pct, F_DO_Pct, DO_mgl, F_DO_mgl ) %>%
  mutate(DateTimeStamp = mdy_hm(DateTimeStamp))

#tz(data_import$DateTimeStamp) <- "America/Los_Angeles"
        


data_long <- data_import %>%
  gather(key = 'parameter', value = 'result', -StationCode, -DateTimeStamp, -F_Temp, -F_DO_Pct, -F_DO_mgl ) %>%
  mutate(qual = ifelse(parameter == "Temp", F_Temp, 
                       ifelse(parameter == "DO_mgl", F_DO_mgl, 
                              ifelse(parameter == "DO_Pct", F_DO_Pct, "ERROR" ))),
         date = as.Date(DateTimeStamp)) %>%
  select(-F_Temp, -F_DO_mgl, -F_DO_Pct) %>%
  # Filter out suspect and other bad data, keep only 0,2,3,4,and 5 labeled data
  filter(grepl("<0>|<2>|<3>|<4>|<5>", qual)) 
  
    


# get unique list of characteristics to run for loop through
unique_characteritics <- unique(data_long$parameter)


#create list for getting data out of loop
monloc_do_list <- list()
sumstatlist <- list()

# For loop for summary statistics -----------------------------------------

# Loop goes through each characteristc and generates summary stats
# After loop, data gets pushed inot single table
for (i in 1:length(unique_characteritics)){
  
  print(paste("Begin",  unique_characteritics[i], "- characteristic", i, "of", length(unique_characteritics)))
  
  # Characteristic for this loop iteration
  char <- unique_characteritics[i]
  
  # Filter so table only contains single characteristic
  results_data_char <- data_long %>%
    filter(parameter == char) %>%
    # generare unique hour field for hourly values and stats
    mutate(hr =  format(DateTimeStamp, "%Y-%j-%H"))
  
  # Simplify to hourly values and Stats
  hrsum <- results_data_char %>%
    group_by(StationCode, hr) %>%
    summarise(date = mean(date),
              hrDTmin = min(DateTimeStamp),
              hrDTmax = max(DateTimeStamp),
              hrN = sum(!is.na(result)),
              hrMean = mean(result, na.rm=TRUE),
              hrMin = min(result, na.rm=TRUE),
              hrMax = max(result, na.rm=TRUE))
  
  
  # For each date, how many hours have hrN > 0
  # remove rows with zero records in an hour. 
  hrdat<- hrsum[which(hrsum$hrN >0),]
  
  # Summarise to daily statistics
  daydat <- hrdat %>%
    group_by(StationCode, date) %>%
    summarise(  dDTmin = min(hrDTmin),
                dDTmax = max(hrDTmax),
                hrNday = length(hrN), 
                dyN = sum(hrN),
                dyMean = mean(hrMean, na.rm=TRUE),
                dyMin = min(hrMin, na.rm=TRUE),
                dyMax = max(hrMax, na.rm=TRUE))
  
  daydat <- daydat %>%
    rowwise() %>%
    mutate(ResultStatusID = ifelse(hrNday >= 22, 'Final', "Rejected")) %>%
    mutate(cmnt =ifelse(hrNday >= 22, "Generated by ORDEQ", ifelse(hrNday <= 22 & hrNday >= 20, 
                                                                   paste0("Generated by ORDEQ; Estimated - ", as.character(hrNday), ' hrs with valid data in day' ), 
                                                                   paste0("Generated by ORDEQ; Rejected - ", as.character(hrNday), ' hrs with valid data in day' )) )) %>%
    mutate(ma.mean7 = as.numeric(""),
           ma.min7 = as.numeric(""),
           ma.mean30 = as.numeric(""),
           ma.max7 = as.numeric(""))
  
  
  #Deal with DO Results
  if (grepl("DO", char)) {
    
    #monitoring location loop
    for(j in 1:length(unique(daydat$StationCode))){
      print(paste("Station", j, "of", length(unique(daydat$StationCode))))
      
      station <- unique(daydat$StationCode)[j]
      
      #Filter dataset to only look at 1 monitoring location at a time
      daydat_station <- daydat %>%
        filter(StationCode == station) %>%
        mutate(startdate7 = as.Date(date) - 6,
               startdate30 = as.Date(date) -30)
      
      # 7 day loop
      # Loops throough each row in the monitoring location dataset
      # And pulls out records that are within the preceding 7 day window
      # If there are at least 6 values, then calculate 7 day min and mean
      # Assigns data back to daydat_station
      print("Begin 7 day moving averages")
      pb <- txtProgressBar(min = 0, max = nrow(daydat_station), style = 3)
      for(k in 1:nrow(daydat_station)){
        
        start7 <- daydat_station$startdate7[k]
        end7 <- daydat_station$date[k] 
        
        station_7day <- daydat_station %>%
          filter(date <= end7 & date >= start7) %>%
          filter(hrNday >= 22) 
        
        ma.mean7 <- ifelse(length(unique(station_7day$date)) >= 6, mean(station_7day$dyMean), NA )
        ma.min7 <- ifelse(length(unique(station_7day$date)) >= 6, mean(station_7day$dyMin), NA )
        
        daydat_station[k,"ma.mean7"] <- ifelse(k >=7, ma.mean7, NA)
        daydat_station[k, "ma.min7"] <- ifelse(k >=7, ma.min7, NA)
        
        
        setTxtProgressBar(pb, k)
        
      } #end of 7day loop
      close(pb)
      # 30 day loop
      # Loops throough each row in the monitoring location dataset
      # And pulls out records that are within the preceding 30 day window
      # If there are at least 29 values, then calculate 30 day mean
      # Assigns data back to daydat_station
      print("Begin 30 day moving averages" )
      pb <- txtProgressBar(min = 0, max = nrow(daydat_station), style = 3)
      for(l in 1:nrow(daydat_station)){
        
        
        start30 <- daydat_station$startdate30[l]
        end30 <- daydat_station$date[l] 
        
        station_30day <- daydat_station %>%
          filter(date <= end30 & date >= start30) %>%
          filter(hrNday >= 22) 
        
        ma.mean30 <- ifelse(length(unique(station_30day$date)) >= 29, mean(station_30day$dyMean), NA )
        
        
        daydat_station[l,"ma.mean30"] <- ifelse(l >= 30, ma.mean30, NA)
        setTxtProgressBar(pb, l)
      } #end of 30day loop
      
      close(pb)
      # Assign dataset filtered to 1 monitoring location to a list for combining outside of for loop
      monloc_do_list[[j]] <- daydat_station
      
      
      
    } # end of monitoring location for loop
    
    # Combine list to single dataframe
    sum_stats <- bind_rows(monloc_do_list)    
    
  } # end of DO if statement
  
  
  ##  TEMPERATURE
  
  if (char == 'Temp' ) {
    
    # Temperature is much easier to calculate, since it needs a complete 7 day record to calculate the 7day moving average
    # This can happen with a simple grouping
    sum_stats <- daydat %>%
      arrange(StationCode, date) %>%
      group_by(StationCode) %>%
      mutate(startdate7 = lag(date, 6, order_by = date),
             macmt = paste(lag(ResultStatusID, 6),
                           lag(ResultStatusID, 5),
                           lag(ResultStatusID, 4),
                           lag(ResultStatusID, 3),
                           lag(ResultStatusID, 2),
                           lag(ResultStatusID, 1),
                           ResultStatusID),
             # flag out which result gets a moving average calculated
             calc7ma = ifelse(startdate7 == (as.Date(date) - 6) & (!grepl("Rejected",macmt )), 1, 0 ))%>%
      mutate(ma.max7 = ifelse(calc7ma == 1 ,round(rollmean(x = dyMax, 7, align = "right", fill = NA),2) , NA )) %>%
      select(-startdate7, -calc7ma, -macmt )
    
  } #end of temp if statement
  
  
  ## Other - just set sum_stats to daydat, since no moving averages need to be generated. 
  if (char != 'Temp' & !grepl("DO", char) ) {
    
    sum_stats <- daydat
    
  } #end of not DO or temp statement
  
  #Assign the char ID to the dataset
  sum_stats <- sum_stats %>%
    mutate(charID = char) 
  
  #Set to list for getting out of for loop
  sumstatlist[[i]] <-  sum_stats
  
  
} # end of characteristics for loop

sumstat <- bind_rows(sumstatlist)

#Gather summary statistics from wide format into long format
#rename summary statistcs to match AWQMS Import COnfiguration
sumstat_long <- sumstat %>%
  rename("Daily Maximum" = dyMax,
         "Daily Minimum" = dyMin,
         "Daily Mean"    = dyMean,
         "7DMADMin"      = ma.min7,
         "7DMADMean"     = ma.mean7,
         "7DMADMax"      = ma.max7,
         "30DMADMean"    = ma.mean30) %>%
  gather(
    "Daily Maximum",
    "Daily Minimum",
    "Daily Mean",
    "7DMADMin",
    "7DMADMean",
    "7DMADMax",
    "30DMADMean",
    key = "StatisticalBasis",
    value = "Result",
    na.rm = TRUE
  ) %>% 
  arrange(StationCode, date) %>%
  mutate(Equipment = "ContinuousPrb")

AQWMS_sum_stat <- sumstat_long %>%
  mutate(r_units = ifelse(charID == "Temp", "deg C", 
                       ifelse(charID == "DO_mgl", "mg/l", 
                              ifelse(charID == "DO_Pct", "% saturatn", "ERROR" ))),
         charID = ifelse(charID == "Temp", "Temperature, water", 
                         ifelse(charID == "DO_mgl", "Dissolved oxygen (DO)", 
                                ifelse(charID == "DO_Pct", "Dissolved oxygen saturation", "ERROR" ))),
         
         RsltTimeBasis = ifelse(StatisticalBasis == "7DMADMin" |
                                  StatisticalBasis == "7DMADMean" |
                                  StatisticalBasis == "7DMADMax", "7 Day", 
                                ifelse(StatisticalBasis == "30DMADMean", "30 Day", "1 Day" )),
         ActivityType = "FMC",
         Result.Analytical.Method.ID = ifelse(charID == "Conductivity", "120.1", 
                                              ifelse(charID == "Dissolved oxygen (DO)", "NFM 6.2.1-LUM", 
                                                     ifelse(charID == "pH","150.1", 
                                                            ifelse(charID == "Temperature, water", "170.1", 
                                                                   ifelse(charID == "Turbidity", "180.1", 
                                                                          ifelse(charID == "Dissolved oxygen saturation", "NFM 6.2.1-LUM", "ERROR" )))))),
         SmplColMthd = "ContinuousPrb",
         SmplColEquip = "Probe/Sensor",
         SmplDepth = "",
         SmplDepthUnit = "",
         SmplColEquipComment = "",
         Samplers = "",
         # Project = Project.ID,
         AnaStartDate = "",
         AnaStartTime = "",
         AnaEndDate = "",
         AnaEndTime = "",
         ActStartDate = format(dDTmax, "%Y-%m-%d"), 
         ActStartTime = "0:00",
         ActEndDate = format(dDTmax, "%Y-%m-%d"),
         ActEndTime = "23:59",
         RsltType = "Calculated",
         ActStartTimeZone = "PST",
         ActEndTimeZone = "PST",
         AnaStartTimeZone = "",
         AnaEndTimeZone = "",
         Result = round(Result, digits = 2)
  ) %>%
  select(charID,
         Result,
         r_units,
         Result.Analytical.Method.ID,
         RsltType,
         ResultStatusID,
         StatisticalBasis,
         RsltTimeBasis,
         cmnt,
         ActivityType,
         StationCode,
         SmplColMthd,
         SmplColEquip,
         SmplDepth,
         SmplDepthUnit,
         SmplColEquipComment,
         Samplers,
         Equipment,
         #Project,
         ActStartDate,
         ActStartTime,
         ActStartTimeZone,
         ActEndDate,
         ActEndTime,
         ActEndTimeZone,
         AnaStartDate,
         AnaStartTime,
         AnaStartTimeZone,
         AnaEndDate,
         AnaEndTime,
         AnaEndTimeZone)

openxlsx::write.xlsx(AQWMS_sum_stat, paste0(tools::file_path_sans_ext(filepath),"-statsum_4_AWQMS.xlsx"))

}