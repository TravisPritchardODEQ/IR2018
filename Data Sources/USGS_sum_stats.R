library(dataRetrieval)
library(tidyverse)
library(zoo)
library(openxlsx)
library(IRlibrary)


########################################################
###            2018 integrated report used           ###
###                 1/1/2008 - 6/29/2018             ###
###             as the daterange. This date          ###
###           range has been entered into AWQMS      ###
########################################################

########################################################
###                 This script only pulls           ###
###               daily max and mins for pH          ###
########################################################



# Remove exisiting Environment
# Warning - This cannot be undone
rm(list=ls())


#save location - Must end with /
save_location <- "E:/NWIS upload/"

#dates
start.date = "2010-01-01"
end.date = "2019-04-21"


# Load in Temp, Do, and monitoring location dataframes for
# 1/1/2008 - 6/29/2018
#load("Data Sources/NWIS_data.RData")


# NWIS codes: https://nwis.waterdata.usgs.gov/usa/nwis/pmcodes/help?codes_help
# data retriveal help: https://pubs.usgs.gov/tm/04/a10/pdf/tm4A10_appendix_1.pdf

# list of NWIS sites in oregon
sites <- whatNWISsites(stateCD = "or",
                       hasDataTypeCd=c("dv","uv"))

USGS_stations <- sites$site_no
statcds = c("00001", "00002", "00003", "00008")
# 00001 = max, 00002 = min, 00003 = mean, 00008 = median
pCodes = c("00010", "00400", "00300", "00301")
# 00010 = temp, 00400 = ph, 00300 = DO mg/L, 00301 = DO sat

# this will get you all data. Way too big for 10 years data
# my computer runs out of resources to convert from wide to long
# need to run each param seperate
# 
# nwis.sum.stats.temp <- readNWISdv(siteNumbers = USGS_stations,
#                              parameterCd = pCodes,
#                              startDate = start.date,
#                              endDate = end.date,
#                              statCd = statcds)

# nwis.sum.stats <- renameNWISColumns(nwis.sum.stats)


# NWIS temperature --------------------------------------------------------



nwis.sum.stats.temp <- readNWISdv(siteNumbers = USGS_stations,
                                  parameterCd = "00010",
                                  startDate = start.date,
                                  endDate = end.date,
                                  statCd = statcds)

nwis.sum.stats.temp <- renameNWISColumns(nwis.sum.stats.temp)



# Calculate 7 day moving average
# lag uses 6 because the 7 day moving average is inclusive of the date
# If 1 day is missing from period, do not caluclate average
temp4ma <- nwis.sum.stats.temp %>%
  arrange(site_no, Date) %>%
  group_by(site_no) %>%
  mutate(startdate = lag(Date, 6, order_by = Date),
         # flag out which result gets a moving average calculated
         calcma = ifelse(startdate == (Date - 6), 1, 0 )) %>%
  mutate(ma = ifelse(calcma == 1, round(rollmean(x = Wtemp_Max, 7, align = "right", fill = NA),1) , NA ))
 
 

nwis.sum.stats.temp.gather <- temp4ma %>%
  gather(Wtemp_Max, 
         Wtemp, 
         Wtemp_Min, 
         ma, key = "stat", value = "result", na.rm = TRUE) %>%
  mutate(qual = ifelse(stat == "Wtemp_Max" | stat == "ma", Wtemp_Max_cd, 
                       ifelse(stat == "Wtemp", Wtemp_cd, 
                              ifelse(stat == "Wtemp_Min", Wtemp_Min_cd, "ERROR" )))) %>%
  select(agency_cd, site_no, Date, stat, result, qual, startdate) %>%
  arrange(site_no, Date)




nwis.sum.stats.temp.AWQMS <- nwis.sum.stats.temp.gather %>%
  ungroup() %>%
  transmute(CharID = "TEMP",
         Result = result,  
         Unit = "deg C",
         Method = "THM01",
         RsltType = "Calculated",
         Qualcd = qual,
         StatisticalBasis = ifelse(stat == "ma","7DMADMax",
                                   ifelse(stat == "Wtemp_Max", "Daily Maximum",
                                   ifelse(stat == "Wtemp", "Daily Mean",
                                          ifelse(stat == "Wtemp_Min", "Daily Minimum",
                                                 "ERROR")))),
         RsltTimeBasis = ifelse(StatisticalBasis == "7DMADMax", "7 day", "1 Day" ),
         DEQ_RsltComment = ifelse(StatisticalBasis == "7DMADMax", "Generated by ORDEQ", "" ),
         ActivityType = "FMC",
         SiteID = site_no,
         SmplColMthd = "ContinuousPrb",
         SmplColEquip = "Probe/Sensor",
         SmplDepth = "",
         SmplDepthUnit = "",
         SmplColEquipComment = "",
         Samplers = "",
         SmplEquipID = "Continuous Probe",
         Project = "Stat Summary",
         ActStartDate = Date,
         ActStartTime = "0:00",
         ActStartTimeZone = "PST",
         ActEndDate = Date,
         ActEndTime = "0:00",
         ActEndTimeZone = "PST",
         AnaStartDate = "",
         AnaStartTime = "",
         AnaStartTimeZone = "",
         AnaEndDate = "",
         AnaEndTime = "",
         AnaEndTimeZone = "",
         ActComment = "",
         ActivityID = paste0(SiteID, ":", gsub("-","",ActStartDate), ":", ActivityType)
         ) %>%
  filter(Qualcd != 'P Eqp',
         Qualcd != 'P Dis',
         Qualcd != 'P Ssn',
         Qualcd != 'A e',
         Qualcd != 'P e')

class(nwis.sum.stats.temp.AWQMS$SiteID) <- c("NULL", "number")


# NWIS pH -----------------------------------------------------------------
# Commenting out due to not using contiuous pH for assessment
nwis.sum.stats.ph <- readNWISdv(siteNumbers = USGS_stations,
                                  parameterCd = "00400",
                                  startDate = start.date,
                                  endDate = end.date,
                                  statCd =  c("00001", "00002"))

nwis.sum.stats.ph <- renameNWISColumns(nwis.sum.stats.ph)

nwis.sum.stats.ph.gather <- nwis.sum.stats.ph %>%
  select(agency_cd, site_no, Date, pH_Max, pH_Max_cd, pH_Min, pH_Min_cd) %>%
  gather(pH_Max, pH_Min, key = "stat", value = "result") %>%
  mutate(qual = case_when(stat == "pH_Max" ~ pH_Max_cd,
                          stat == "pH_Min" ~ pH_Min_cd,
                          TRUE ~ "ERROR")) %>%
  filter(!is.na(result)) %>%
  select(agency_cd, site_no, Date, stat, result, qual) %>%
  arrange(site_no, Date)

  
     
nwis.sum.stats.pH.AWQMS <- nwis.sum.stats.ph.gather %>%
  transmute(CharID = "pH",
            Result = result,  
            Unit = "None",
            Method = "pH-150.1",
            RsltType = "Calculated",
            Qualcd = qual,
            StatisticalBasis = case_when(stat == "pH_Max" ~ "Daily Maximum",
                                         stat == "pH_Median" ~ 'Daily Median',
                                         stat == "pH_Min" ~ "Daily Minimum",
                                         stat == "pH" ~ "Daily Mean",
                                         TRUE ~ "ERROR"),
            RsltTimeBasis = ifelse(StatisticalBasis == "7DMADMax", "7 day", "1 Day" ),
            DEQ_RsltComment = ifelse(StatisticalBasis == "7DMADMax", "Generated by ORDEQ", "" ),
            ActivityType = "FMC",
            SiteID = site_no,
            SmplColMthd = "ContinuousPrb",
            SmplColEquip = "Probe/Sensor",
            SmplDepth = "",
            SmplDepthUnit = "",
            SmplColEquipComment = "",
            Samplers = "",
            SmplEquipID = "Continuous Probe",
            Project = "Stat Summary",
            ActStartDate = Date,
            ActStartTime = "0:00",
            ActStartTimeZone = "PST",
            ActEndDate = Date,
            ActEndTime = "0:00",
            ActEndTimeZone = "PST",
            AnaStartDate = "",
            AnaStartTime = "",
            AnaStartTimeZone = "",
            AnaEndDate = "",
            AnaEndTime = "",
            AnaEndTimeZone = "",
            ActComment = "",
            ActivityID = paste0(SiteID, ":", gsub("-","",ActStartDate), ":", ActivityType)
  ) %>%
  filter(Qualcd != 'P Eqp',
         Qualcd != 'P Dis',
         Qualcd != 'P Ssn',
         Qualcd != 'A e',
         Qualcd != 'P e')


class(nwis.sum.stats.pH.AWQMS$SiteID) <- c("NULL", "number")
# NWIS DO conc ------------------------------------------------------------

nwis.sum.stats.DO <- readNWISdv(siteNumbers = USGS_stations,
                                parameterCd = "00300",
                                startDate = start.date,
                                endDate = end.date,
                                statCd = statcds)


nwis.sum.stats.DO <- renameNWISColumns(nwis.sum.stats.DO)


# Calculate moving averages. If 1 or more daya are missing from period, do not caluclate average
DO4ma <- nwis.sum.stats.DO %>%
  arrange(site_no, Date) %>%
  group_by(site_no) %>%
  mutate(startdate7 = lag(Date, 6, order_by = Date),
         # flag out which result gets a moving average calculated
         calc7ma = ifelse(startdate7 == (Date - 6), 1, 0 ),
         startdate30 = lag(Date, 29, order_by = Date),
         calc30ma = ifelse(startdate30 == (Date - 29), 1, 0 )) %>%
  mutate(ma.mean7 = ifelse(calc7ma == 1, round(rollmean(x = DO, 7, align = "right", fill = NA),1) , NA ),
         ma.mean30 = ifelse(calc30ma == 1, round(rollmean(x = DO, 30, align = "right", fill = NA),1) , NA ),
         ma.min7 = ifelse(calc7ma == 1, round(rollmean(x = DO_Min, 7, align = "right", fill = NA),1) , NA )) 


nwis.sum.stats.DO.gather <- DO4ma %>%
  gather(DO_Max, DO, DO_Min, ma.mean7, ma.mean30,ma.min7,   key = "stat", value = "result", na.rm = TRUE) %>%
  mutate(qual = ifelse(stat == "DO_Max", DO_Max_cd, 
                       ifelse(stat == "DO" | stat == "ma.mean7" | stat == "ma.mean30", DO_cd, 
                              ifelse(stat == "DO_Min" | stat == "ma.min7", DO_Min_cd, "ERROR" )))) %>%
  select(agency_cd, site_no, Date, stat, result, qual, startdate7, startdate30 )


nwis.sum.stats.DO.AWQMS <- nwis.sum.stats.DO.gather %>%
  ungroup() %>%
  transmute(CharID = "DO",
            Result = result,
            Unit = "mg/L",
            Method = "LUMIN",
            RsltType = "Calculated",
            Qualcd = qual,
            StatisticalBasis = ifelse(stat == "ma.mean7","7DMADMean",
                                      ifelse(stat == "DO_Max", "Daily Maximum",
                                             ifelse(stat == "DO", "Daily Mean",
                                                    ifelse(stat == "DO_Min", "Daily Minimum",
                                                           ifelse(stat == "ma.mean30", "30DMADMean",
                                                                  ifelse(stat == "ma.min7", "7DMADMin", "ERROR")))))),
            RsltTimeBasis = ifelse(StatisticalBasis == "7DMADMean" | StatisticalBasis == "7DMADMin", "7 day",
                                   ifelse(StatisticalBasis == "30DMADMean", "30 Day", "1 Day" )),
            DEQ_RsltComment = ifelse(StatisticalBasis == "7DMADMean" |
                                       StatisticalBasis == "7DMADMin" |
                                       StatisticalBasis == "30DMADMean", "Generated by ORDEQ", "" ),
            ActivityType = "FMC",
            SiteID = site_no,
            SmplColMthd = "ContinuousPrb",
            SmplColEquip = "Probe/Sensor",
            SmplDepth = "",
            SmplDepthUnit = "",
            SmplColEquipComment = "",
            Samplers = "",
            SmplEquipID = "Continuous Probe",
            Project = "Stat Summary",
            ActStartDate = Date,
            ActStartTime = "0:00",
            ActStartTimeZone = "PST",
            ActEndDate = Date,
            ActEndTime = "0:00",
            ActEndTimeZone = "PST",
            AnaStartDate = "",
            AnaStartTime = "",
            AnaStartTimeZone = "",
            AnaEndDate = "",
            AnaEndTime = "",
            AnaEndTimeZone = "",
            ActComment = "",
            ActivityID = paste0(SiteID, ":", gsub("-","",ActStartDate), ":", ActivityType)) %>%
  arrange(SiteID, ActStartDate)%>%
  filter(Qualcd != 'P Eqp',
         Qualcd != 'P Dis',
         Qualcd != 'P Ssn',
         Qualcd != 'A e',
         Qualcd != 'P e')

class(nwis.sum.stats.DO.AWQMS$SiteID) <- c("NULL", "number")



#write_csv(nwis.sum.stats.DO.gather, "nwis_DO_sum_stats_long.csv")



# NWIS DO sat ------------------------------------------------------------
#### There does not appear to be any DO sat data in NWIS for Oregon
# nwis.sum.stats.DOsat <- readNWISdv(siteNumbers = USGS_stations,
#                                 parameterCd = "00301",
#                                 startDate = start.date,
#                                 endDate = end.date,
#                                 statCd = statcds)
# 
# 
# nwis.sum.stats.DOsat <- renameNWISColumns(nwis.sum.stats.DOsat)


# #list of sites from the sum.stats table
# nwis_sum_stat_sites <- unique(nwis.sum.stats$site_no)
# 
# #pull site info from NWIS for sites identified in sum.stats table
# nwis_sites <- readNWISsite(nwis_sum_stat_sites)




# Monitoring station information ------------------------------------------

#read in county query
county_query <- read_csv("./Data Sources/county_codes.csv", col_types = c(col_character())) %>%
  mutate(county_cd = as.character(county_cd)) %>%
  select(county_cd, county_nm)

if (nrow(nwis.sum.stats.DO) > 0 &
    nrow(nwis.sum.stats.ph) > 0) {
  nwissites <-
    unique(c(
      unique(nwis.sum.stats.DO.AWQMS$SiteID),
      unique(nwis.sum.stats.temp.AWQMS$SiteID),
      unique(nwis.sum.stats.pH.AWQMS$SiteID)
    ))
  
} else if (nrow(nwis.sum.stats.DO) > 0 &
           nrow(nwis.sum.stats.ph) == 0) {
  nwissites <-
    unique(c(
      unique(nwis.sum.stats.DO.AWQMS$SiteID),
      unique(nwis.sum.stats.temp.AWQMS$SiteID)
    ))
  
} else {
  nwissites <- unique(nwis.sum.stats.temp.AWQMS$SiteID)
}



nwissites <- readNWISsite(unique(nwissites))


nwis.sites.AWQMS <- nwissites %>%
  left_join(county_query, by = "county_cd") %>% 
  transmute(Stationkey = site_no,
            Desc = station_nm,
            SiteComments = "",
            MonLocType = ifelse(site_tp_cd == "ST", 'River/Stream', 
                                ifelse(site_tp_cd == "LK", "Lake", 
                                       ifelse(site_tp_cd == "ST-CA", "Canal Transport", 
                                              ifelse(site_tp_cd == "GW", "Well", "ERROR" )))),
            COUNTY = county_nm,
            STATE = "OR",
            Country = "US",
            HUC8 = huc_cd,
            HUC12 = "",
            TribalLand = "",
            TribalName = "",
            CreateDate = "",
            T_R_S = "",
            Lat = dec_lat_va,
            Long = dec_long_va,
            Datum = dec_coord_datum_cd,
            CollMethod = "Interpolation-Digital Map Source",
            MapScale = map_scale_fc,
            Comments = "",
            WellType = ifelse(MonLocType == "Well", "Monitoring", ""),
            WellForm = "",
            WellAquiferName = ifelse(MonLocType == "Well", nat_aqfr_cd, ""),
            WellDepth = ifelse(MonLocType == "Well", well_depth_va, ""),
            WellDepthUnit = "ft",
            AltLocID = "",
            AltLocName = "",
            EcoRegion3 = "",
            EcoRegion4 = "",
            Reachcode = "",
            GNIS_Name = "",
            AU_ID = ""
            ) 
            
# remove NAs
nwis.sites.AWQMS[is.na(nwis.sites.AWQMS)] <- ""            
            
            

# write.csv(nwis.sum.stats.DO.AWQMS, "Data Sources/NWIS_Do_sum_stat_AWQMS.csv", row.names = FALSE)
# write.csv(nwis.sum.stats.temp.AWQMS, "Data Sources/NWIS_Temp_sum_stat_AWQMS.csv", row.names = FALSE)
# 
# save(nwis.sites.AWQMS, nwis.sum.stats.DO.AWQMS, nwis.sum.stats.temp.AWQMS, file = "Data Sources/NWIS_data.RData")
# save.image(file= "Data Sources/NWIS_environment.RData")




# Write csvs --------------------------------------------------------------



# Data_Split <- function(df) {
#   
#   # Max row size of file 
#   chunk <- 500000
#   
#   n <- nrow(df)
#   r  <- rep(1:ceiling(n/chunk),each=chunk)[1:n]
#   d <- split(df,r)
#   
#   for(i in 1:length(d)){
#     
#     shortdf <- as.data.frame(d[i])
#     names(shortdf) <- names(df)
#     write.csv(shortdf, file=paste0("A:/Integrated_Report/DataSources/USGS_NWIS/",deparse(substitute(df)), "-", i, ".csv"))
#     
#   }
#   
# }
# 
# Data_Split(nwis.sites.AWQMS)
# Data_Split(nwis.sum.stats.DO.AWQMS)
# Data_Split(nwis.sum.stats.temp.AWQMS)

NWIS_data <- bind_rows(nwis.sum.stats.temp.AWQMS
                         ,nwis.sum.stats.DO.AWQMS
                         ,nwis.sum.stats.pH.AWQMS 
                         ) 



write.csv(nwis.sites.AWQMS, paste0(save_location,"NWIS_Monitoring_Locations.csv"), row.names = FALSE)
Data_Split_AWQMS(NWIS_data, split_on = "SiteID", size = 100000, filepath = save_location)




# Cont DO data ------------------------------------------------------------

# 
# cont_DO <- readNWISuv(siteNumbers = unique(nwis.sum.stats.DO$site_no),
#            parameterCd = "00300",
#            startDate = start.date,
#            endDate = end.date)
# 
# cont_DO <- readNWISuv(siteNumbers = "11507501",
#                       parameterCd = "00300",
#                       startDate = start.date,
#                       endDate = end.date,
#                       tz = "UTC")
# cont_DO <-  renameNWISColumns(cont_DO)
